# Provider
PROVIDER=ollama

# Ollama Models
OLLAMA_CHAT_MODEL=llama3.2
OLLAMA_EMBED_MODEL=nomic-embed-text

# Paths
PDF_DIR=data/pdfs
VECTOR_DIR=vectorstore/faiss_index

# RAG Settings
TOP_K=3
CHUNK_SIZE=800
CHUNK_OVERLAP=120

#front-end
VITE_API_BASE_URL=http://localhost:8000

